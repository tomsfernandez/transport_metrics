{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "from pyspark.sql import SparkSession, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"BaPoints\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[route_id: string, trip_id: string, last_stop_id: string, timestamp: bigint, vehicle_id: string, vehicle_label: string, start_time: string, start_date: string, latitude: double, longitude: double, speed: double]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = spark.read.json('../Datasets/ba_points/points_50000_new.json')\n",
    "points = points.drop('_id').selectExpr('_vehicle._trip._route_id as route_id',\n",
    "                              '_vehicle._trip._trip_id as trip_id',\n",
    "                              '_vehicle._stop_id as last_stop_id',\n",
    "                              '_vehicle._timestamp as timestamp',\n",
    "                              '_vehicle._vehicle._id as vehicle_id',\n",
    "                              '_vehicle._vehicle._label as vehicle_label',\n",
    "                              '_vehicle._trip._start_time as start_time',\n",
    "                              '_vehicle._trip._start_date as start_date',         \n",
    "                              '_vehicle._position._latitude as latitude',\n",
    "                              '_vehicle._position._longitude as longitude',\n",
    "                              '_vehicle._position._speed as speed')\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f5981cdb3c6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Datasets/ba_points/routes.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroutes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'route_url'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'route_color'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'route_text_color'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "routes = spark.read.csv('../Datasets/ba_points/routes.txt', inferSchema=True, header=True)\n",
    "routes = routes.drop('route_url','route_color', 'route_text_color')\n",
    "routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------+\n",
      "|trip_id|stop_id|stop_sequence|\n",
      "+-------+-------+-------------+\n",
      "| 101HI0|2033214|           15|\n",
      "| 101HI0| 202889|           16|\n",
      "| 101HI0|2033139|           17|\n",
      "| 101HI0| 201738|           18|\n",
      "| 101HI0| 201633|           19|\n",
      "| 101HI0| 201525|           20|\n",
      "| 101HI0| 202096|           21|\n",
      "| 101HI0| 202089|           22|\n",
      "| 101HI0| 205634|           23|\n",
      "| 101HI0| 202051|           24|\n",
      "| 101HI0|2032198|           25|\n",
      "| 101HI0| 201476|           26|\n",
      "| 101HI0| 206126|           27|\n",
      "| 101HI0| 201398|           28|\n",
      "| 101HI0| 205686|           29|\n",
      "| 101HI0| 205659|           30|\n",
      "| 101HI0|2033223|           31|\n",
      "| 101HI0|  20796|           32|\n",
      "| 101HI0| 203054|           33|\n",
      "| 101HI0| 201079|           34|\n",
      "+-------+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_trips = spark.read.csv('../Datasets/ba_points/stop_times.txt', inferSchema=True, header=True)\n",
    "stop_trips = stop_trips.drop('arrival_time', 'departure_time', 'stop_headsign',\n",
    "                             'pickup_type', 'drop_off_type', 'shape_dist_traveled')\n",
    "stop_trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+-------------+---------------+------------+-----------+\n",
      "|route_id|service_id| trip_id|trip_headsign|trip_short_name|direction_id|exceptional|\n",
      "+--------+----------+--------+-------------+---------------+------------+-----------+\n",
      "|    3713|         2|229003-1|   a BÂº Nuevo|     3713SI0057|           0|          0|\n",
      "+--------+----------+--------+-------------+---------------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips = spark.read.csv('../Datasets/ba_points/trips.txt', inferSchema=True, header=True)\n",
    "trips = trips.drop('block_id', 'shape_id', 'wheelchair_accessible', 'bikes_allowed')\n",
    "trips.where(trips.trip_id == '229003-1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+----------+---------+\n",
      "|   stop_id|stop_code|           stop_name|  stop_lat| stop_lon|\n",
      "+----------+---------+--------------------+----------+---------+\n",
      "|6539109469|     null|AVENIDA PATRICIOS...|-34.684054|-58.68259|\n",
      "+----------+---------+--------------------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stops = spark.read.csv('../Datasets/ba_points/stops.txt', inferSchema=True, header=True)\n",
    "stops.drop('stop_timezone', 'wheelchair_boarding', 'stop_desc', 'zone_id', 'stop_url', \n",
    "           'location_type', 'parent_station').where(stops.stop_id == '6539109469').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[trip_id: string, route_id: int, service_id: string, trip_headsign: string, trip_short_name: string, direction_id: int, stop_id: bigint, stop_sequence: int]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_with_stops = trips.join(stop_trips, 'trip_id').orderBy('route_id', 'stop_sequence')\n",
    "trips_with_stops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
